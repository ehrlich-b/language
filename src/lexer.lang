// src/lexer.lang - Lexer for self-hosting compiler
// Tokenizes source code into a stream of tokens

// ============================================================
// Token Types (constants)
// ============================================================

// Special
var TOKEN_EOF i64 = 0;
var TOKEN_ERROR i64 = 1;

// Literals
var TOKEN_IDENT i64 = 2;
var TOKEN_NUMBER i64 = 3;
var TOKEN_STRING i64 = 4;

// Keywords
var TOKEN_FUNC i64 = 5;
var TOKEN_VAR i64 = 6;
var TOKEN_STRUCT i64 = 7;
var TOKEN_IF i64 = 8;
var TOKEN_ELSE i64 = 9;
var TOKEN_WHILE i64 = 10;
var TOKEN_RETURN i64 = 11;
var TOKEN_TRUE i64 = 12;
var TOKEN_FALSE i64 = 13;
var TOKEN_NIL i64 = 14;

// Type keywords
var TOKEN_I8 i64 = 15;
var TOKEN_I16 i64 = 16;
var TOKEN_I32 i64 = 17;
var TOKEN_I64 i64 = 18;
var TOKEN_U8 i64 = 19;
var TOKEN_U16 i64 = 20;
var TOKEN_U32 i64 = 21;
var TOKEN_U64 i64 = 22;
var TOKEN_BOOL i64 = 23;
var TOKEN_VOID i64 = 24;

// Operators
var TOKEN_PLUS i64 = 25;      // +
var TOKEN_MINUS i64 = 26;     // -
var TOKEN_STAR i64 = 27;      // *
var TOKEN_SLASH i64 = 28;     // /
var TOKEN_PERCENT i64 = 29;   // %
var TOKEN_AMP i64 = 30;       // &
var TOKEN_BANG i64 = 31;      // !
var TOKEN_EQ i64 = 32;        // =
var TOKEN_EQEQ i64 = 33;      // ==
var TOKEN_BANGEQ i64 = 34;    // !=
var TOKEN_LT i64 = 35;        // <
var TOKEN_GT i64 = 36;        // >
var TOKEN_LTEQ i64 = 37;      // <=
var TOKEN_GTEQ i64 = 38;      // >=
var TOKEN_AMPAMP i64 = 39;    // &&
var TOKEN_PIPEPIPE i64 = 40;  // ||

// Punctuation
var TOKEN_LPAREN i64 = 41;    // (
var TOKEN_RPAREN i64 = 42;    // )
var TOKEN_LBRACE i64 = 43;    // {
var TOKEN_RBRACE i64 = 44;    // }
var TOKEN_LBRACKET i64 = 45;  // [
var TOKEN_RBRACKET i64 = 46;  // ]
var TOKEN_COMMA i64 = 47;     // ,
var TOKEN_SEMICOLON i64 = 48; // ;
var TOKEN_DOT i64 = 49;       // .
var TOKEN_COLON i64 = 50;     // :
var TOKEN_COLONEQ i64 = 51;   // :=

// ============================================================
// Token struct
// ============================================================

struct Token {
    type_tok i64;
    lexeme *u8;
    lexeme_len i64;
    line i64;
    col i64;
}

// Accessor functions for backward compatibility
// These cast *u8 to *Token and use field access

func tok_type(tok *u8) i64 {
    var t *Token = tok;
    return t.type_tok;
}

func tok_set_type(tok *u8, typ i64) void {
    var t *Token = tok;
    t.type_tok = typ;
}

func tok_lexeme(tok *u8) *u8 {
    var t *Token = tok;
    return t.lexeme;
}

func tok_set_lexeme(tok *u8, ptr *u8) void {
    var t *Token = tok;
    t.lexeme = ptr;
}

func tok_lexeme_len(tok *u8) i64 {
    var t *Token = tok;
    return t.lexeme_len;
}

func tok_set_lexeme_len(tok *u8, len i64) void {
    var t *Token = tok;
    t.lexeme_len = len;
}

func tok_line(tok *u8) i64 {
    var t *Token = tok;
    return t.line;
}

func tok_set_line(tok *u8, ln i64) void {
    var t *Token = tok;
    t.line = ln;
}

func tok_col(tok *u8) i64 {
    var t *Token = tok;
    return t.col;
}

func tok_set_col(tok *u8, c i64) void {
    var t *Token = tok;
    t.col = c;
}

func tok_alloc() *u8 {
    return alloc(40);
}

// ============================================================
// Lexer state (global)
// ============================================================

var lex_source *u8 = nil;
var lex_source_len i64 = 0;
var lex_start i64 = 0;
var lex_current i64 = 0;
var lex_line i64 = 1;
var lex_col i64 = 1;
var lex_start_col i64 = 1;

func lexer_init(source *u8) void {
    lex_source = source;
    lex_source_len = strlen(source);
    lex_start = 0;
    lex_current = 0;
    lex_line = 1;
    lex_col = 1;
    lex_start_col = 1;
}

// ============================================================
// Character helpers
// ============================================================

func is_alpha(c u8) bool {
    if c >= 97 {  // 'a'
        if c <= 122 {  // 'z'
            return true;
        }
    }
    if c >= 65 {  // 'A'
        if c <= 90 {  // 'Z'
            return true;
        }
    }
    if c == 95 {  // '_'
        return true;
    }
    return false;
}

func is_digit(c u8) bool {
    if c >= 48 {  // '0'
        if c <= 57 {  // '9'
            return true;
        }
    }
    return false;
}

func is_alphanumeric(c u8) bool {
    return is_alpha(c) || is_digit(c);
}

// ============================================================
// Lexer helpers
// ============================================================

func lex_is_at_end() bool {
    return lex_current >= lex_source_len;
}

func lex_peek() u8 {
    if lex_is_at_end() {
        return 0;
    }
    return *(lex_source + lex_current);
}

func lex_peek_next() u8 {
    if lex_current + 1 >= lex_source_len {
        return 0;
    }
    return *(lex_source + lex_current + 1);
}

func lex_advance() u8 {
    var c u8 = *(lex_source + lex_current);
    lex_current = lex_current + 1;
    lex_col = lex_col + 1;
    return c;
}

func lex_match(expected u8) bool {
    if lex_is_at_end() {
        return false;
    }
    if *(lex_source + lex_current) != expected {
        return false;
    }
    lex_current = lex_current + 1;
    lex_col = lex_col + 1;
    return true;
}

// ============================================================
// Token creation
// ============================================================

func make_token(tok_type i64) *u8 {
    var tok *u8 = tok_alloc();
    tok_set_type(tok, tok_type);
    tok_set_lexeme(tok, lex_source + lex_start);
    tok_set_lexeme_len(tok, lex_current - lex_start);
    tok_set_line(tok, lex_line);
    tok_set_col(tok, lex_start_col);
    return tok;
}

func error_token(msg *u8) *u8 {
    var tok *u8 = tok_alloc();
    tok_set_type(tok, TOKEN_ERROR);
    tok_set_lexeme(tok, msg);
    tok_set_lexeme_len(tok, strlen(msg));
    tok_set_line(tok, lex_line);
    tok_set_col(tok, lex_start_col);
    return tok;
}

// ============================================================
// Skip whitespace and comments
// ============================================================

func skip_block_comment() void {
    lex_advance();  // consume /
    lex_advance();  // consume *
    var done i64 = 0;
    while !lex_is_at_end() && done == 0 {
        if lex_peek() == 42 && lex_peek_next() == 47 {
            lex_advance();  // consume *
            lex_advance();  // consume /
            done = 1;
        } else {
            if lex_peek() == 10 {
                lex_line = lex_line + 1;
                lex_col = 0;
            }
            lex_advance();
        }
    }
}

func skip_whitespace() void {
    var done i64 = 0;
    while done == 0 {
        if lex_is_at_end() {
            done = 1;
        } else {
            var c u8 = lex_peek();

            if c == 32 || c == 9 || c == 13 {  // space, tab, CR
                lex_advance();
            } else if c == 10 {  // newline
                lex_line = lex_line + 1;
                lex_col = 0;
                lex_advance();
            } else if c == 47 {  // '/'
                if lex_peek_next() == 47 {  // '//' line comment
                    while !lex_is_at_end() && lex_peek() != 10 {
                        lex_advance();
                    }
                } else if lex_peek_next() == 42 {  // '/*' block comment
                    skip_block_comment();
                } else {
                    done = 1;
                }
            } else {
                done = 1;
            }
        }
    }
}

// ============================================================
// Keyword lookup
// ============================================================

// Check if lexeme matches a keyword, accounting for length
func lexeme_eq(kw *u8) bool {
    var kw_len i64 = strlen(kw);
    var lex_len i64 = lex_current - lex_start;
    if kw_len != lex_len {
        return false;
    }
    var i i64 = 0;
    while i < kw_len {
        if *(lex_source + lex_start + i) != *(kw + i) {
            return false;
        }
        i = i + 1;
    }
    return true;
}

func check_keyword() i64 {
    // Keywords
    if lexeme_eq("func") { return TOKEN_FUNC; }
    if lexeme_eq("var") { return TOKEN_VAR; }
    if lexeme_eq("struct") { return TOKEN_STRUCT; }
    if lexeme_eq("if") { return TOKEN_IF; }
    if lexeme_eq("else") { return TOKEN_ELSE; }
    if lexeme_eq("while") { return TOKEN_WHILE; }
    if lexeme_eq("return") { return TOKEN_RETURN; }
    if lexeme_eq("true") { return TOKEN_TRUE; }
    if lexeme_eq("false") { return TOKEN_FALSE; }
    if lexeme_eq("nil") { return TOKEN_NIL; }

    // Type keywords
    if lexeme_eq("i8") { return TOKEN_I8; }
    if lexeme_eq("i16") { return TOKEN_I16; }
    if lexeme_eq("i32") { return TOKEN_I32; }
    if lexeme_eq("i64") { return TOKEN_I64; }
    if lexeme_eq("u8") { return TOKEN_U8; }
    if lexeme_eq("u16") { return TOKEN_U16; }
    if lexeme_eq("u32") { return TOKEN_U32; }
    if lexeme_eq("u64") { return TOKEN_U64; }
    if lexeme_eq("bool") { return TOKEN_BOOL; }
    if lexeme_eq("void") { return TOKEN_VOID; }

    // Built-in (treated like keyword)
    if lexeme_eq("syscall") { return TOKEN_IDENT; }

    return TOKEN_IDENT;
}

// ============================================================
// Scan specific token types
// ============================================================

func scan_identifier() *u8 {
    while is_alphanumeric(lex_peek()) {
        lex_advance();
    }
    return make_token(check_keyword());
}

func scan_number() *u8 {
    while is_digit(lex_peek()) {
        lex_advance();
    }
    return make_token(TOKEN_NUMBER);
}

func scan_string() *u8 {
    while !lex_is_at_end() && lex_peek() != 34 {  // '"'
        if lex_peek() == 10 {  // newline
            lex_line = lex_line + 1;
            lex_col = 0;
        }
        if lex_peek() == 92 && lex_peek_next() != 0 {  // backslash escape
            lex_advance();  // consume backslash
        }
        lex_advance();
    }

    if lex_is_at_end() {
        return error_token("unterminated string");
    }

    lex_advance();  // closing quote
    return make_token(TOKEN_STRING);
}

// ============================================================
// Main scan function
// ============================================================

func scan_token() *u8 {
    skip_whitespace();
    lex_start = lex_current;
    lex_start_col = lex_col;

    if lex_is_at_end() {
        return make_token(TOKEN_EOF);
    }

    var c u8 = lex_advance();

    if is_alpha(c) {
        return scan_identifier();
    }
    if is_digit(c) {
        return scan_number();
    }

    // Single-char tokens
    if c == 40 { return make_token(TOKEN_LPAREN); }    // '('
    if c == 41 { return make_token(TOKEN_RPAREN); }    // ')'
    if c == 123 { return make_token(TOKEN_LBRACE); }   // '{'
    if c == 125 { return make_token(TOKEN_RBRACE); }   // '}'
    if c == 91 { return make_token(TOKEN_LBRACKET); }  // '['
    if c == 93 { return make_token(TOKEN_RBRACKET); }  // ']'
    if c == 44 { return make_token(TOKEN_COMMA); }     // ','
    if c == 59 { return make_token(TOKEN_SEMICOLON); } // ';'
    if c == 46 { return make_token(TOKEN_DOT); }       // '.'
    if c == 43 { return make_token(TOKEN_PLUS); }      // '+'
    if c == 45 { return make_token(TOKEN_MINUS); }     // '-'
    if c == 42 { return make_token(TOKEN_STAR); }      // '*'
    if c == 47 { return make_token(TOKEN_SLASH); }     // '/'
    if c == 37 { return make_token(TOKEN_PERCENT); }   // '%'

    // Two-char tokens
    if c == 38 {  // '&'
        if lex_match(38) { return make_token(TOKEN_AMPAMP); }  // '&&'
        return make_token(TOKEN_AMP);
    }
    if c == 124 {  // '|'
        if lex_match(124) { return make_token(TOKEN_PIPEPIPE); }  // '||'
        return error_token("unexpected character '|'");
    }
    if c == 33 {  // '!'
        if lex_match(61) { return make_token(TOKEN_BANGEQ); }  // '!='
        return make_token(TOKEN_BANG);
    }
    if c == 61 {  // '='
        if lex_match(61) { return make_token(TOKEN_EQEQ); }  // '=='
        return make_token(TOKEN_EQ);
    }
    if c == 60 {  // '<'
        if lex_match(61) { return make_token(TOKEN_LTEQ); }  // '<='
        return make_token(TOKEN_LT);
    }
    if c == 62 {  // '>'
        if lex_match(61) { return make_token(TOKEN_GTEQ); }  // '>='
        return make_token(TOKEN_GT);
    }
    if c == 58 {  // ':'
        if lex_match(61) { return make_token(TOKEN_COLONEQ); }  // ':='
        return make_token(TOKEN_COLON);
    }
    if c == 34 {  // '"'
        return scan_string();
    }

    return error_token("unexpected character");
}

// ============================================================
// Debug helpers
// ============================================================

func print_token_type(t i64) void {
    if t == TOKEN_EOF { print("EOF"); return; }
    if t == TOKEN_ERROR { print("ERROR"); return; }
    if t == TOKEN_IDENT { print("IDENT"); return; }
    if t == TOKEN_NUMBER { print("NUMBER"); return; }
    if t == TOKEN_STRING { print("STRING"); return; }
    if t == TOKEN_FUNC { print("func"); return; }
    if t == TOKEN_VAR { print("var"); return; }
    if t == TOKEN_STRUCT { print("struct"); return; }
    if t == TOKEN_IF { print("if"); return; }
    if t == TOKEN_ELSE { print("else"); return; }
    if t == TOKEN_WHILE { print("while"); return; }
    if t == TOKEN_RETURN { print("return"); return; }
    if t == TOKEN_TRUE { print("true"); return; }
    if t == TOKEN_FALSE { print("false"); return; }
    if t == TOKEN_NIL { print("nil"); return; }
    if t == TOKEN_I8 { print("i8"); return; }
    if t == TOKEN_I16 { print("i16"); return; }
    if t == TOKEN_I32 { print("i32"); return; }
    if t == TOKEN_I64 { print("i64"); return; }
    if t == TOKEN_U8 { print("u8"); return; }
    if t == TOKEN_U16 { print("u16"); return; }
    if t == TOKEN_U32 { print("u32"); return; }
    if t == TOKEN_U64 { print("u64"); return; }
    if t == TOKEN_BOOL { print("bool"); return; }
    if t == TOKEN_VOID { print("void"); return; }
    if t == TOKEN_PLUS { print("+"); return; }
    if t == TOKEN_MINUS { print("-"); return; }
    if t == TOKEN_STAR { print("*"); return; }
    if t == TOKEN_SLASH { print("/"); return; }
    if t == TOKEN_PERCENT { print("%"); return; }
    if t == TOKEN_AMP { print("&"); return; }
    if t == TOKEN_BANG { print("!"); return; }
    if t == TOKEN_EQ { print("="); return; }
    if t == TOKEN_EQEQ { print("=="); return; }
    if t == TOKEN_BANGEQ { print("!="); return; }
    if t == TOKEN_LT { print("<"); return; }
    if t == TOKEN_GT { print(">"); return; }
    if t == TOKEN_LTEQ { print("<="); return; }
    if t == TOKEN_GTEQ { print(">="); return; }
    if t == TOKEN_AMPAMP { print("&&"); return; }
    if t == TOKEN_PIPEPIPE { print("||"); return; }
    if t == TOKEN_LPAREN { print("("); return; }
    if t == TOKEN_RPAREN { print(")"); return; }
    if t == TOKEN_LBRACE { print("{"); return; }
    if t == TOKEN_RBRACE { print("}"); return; }
    if t == TOKEN_LBRACKET { print("["); return; }
    if t == TOKEN_RBRACKET { print("]"); return; }
    if t == TOKEN_COMMA { print(","); return; }
    if t == TOKEN_SEMICOLON { print(";"); return; }
    if t == TOKEN_DOT { print("."); return; }
    if t == TOKEN_COLON { print(":"); return; }
    if t == TOKEN_COLONEQ { print(":="); return; }
    print("UNKNOWN");
}

// Print n chars from a pointer
func print_n(s *u8, n i64) void {
    file_write(1, s, n);
}

func print_token(tok *u8) void {
    print("[");
    print_int(tok_line(tok));
    print(":");
    print_int(tok_col(tok));
    print("] ");
    print_token_type(tok_type(tok));
    print(" '");
    print_n(tok_lexeme(tok), tok_lexeme_len(tok));
    println("'");
}
