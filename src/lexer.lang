// src/lexer.lang - Lexer for self-hosting compiler
// Tokenizes source code into a stream of tokens

// ============================================================
// Token Types (constants)
// ============================================================

// Special
var TOKEN_EOF i64 = 0;
var TOKEN_ERROR i64 = 1;

// Literals
var TOKEN_IDENT i64 = 2;
var TOKEN_NUMBER i64 = 3;
var TOKEN_STRING i64 = 4;

// Keywords
var TOKEN_FUNC i64 = 5;
var TOKEN_VAR i64 = 6;
var TOKEN_STRUCT i64 = 7;
var TOKEN_IF i64 = 8;
var TOKEN_ELSE i64 = 9;
var TOKEN_WHILE i64 = 10;
var TOKEN_RETURN i64 = 11;
var TOKEN_TRUE i64 = 12;
var TOKEN_FALSE i64 = 13;
var TOKEN_NIL i64 = 14;

// Type keywords
var TOKEN_I8 i64 = 15;
var TOKEN_I16 i64 = 16;
var TOKEN_I32 i64 = 17;
var TOKEN_I64 i64 = 18;
var TOKEN_U8 i64 = 19;
var TOKEN_U16 i64 = 20;
var TOKEN_U32 i64 = 21;
var TOKEN_U64 i64 = 22;
var TOKEN_BOOL i64 = 23;
var TOKEN_VOID i64 = 24;

// Operators
var TOKEN_PLUS i64 = 25;      // +
var TOKEN_MINUS i64 = 26;     // -
var TOKEN_STAR i64 = 27;      // *
var TOKEN_SLASH i64 = 28;     // /
var TOKEN_PERCENT i64 = 29;   // %
var TOKEN_AMP i64 = 30;       // &
var TOKEN_BANG i64 = 31;      // !
var TOKEN_EQ i64 = 32;        // =
var TOKEN_EQEQ i64 = 33;      // ==
var TOKEN_BANGEQ i64 = 34;    // !=
var TOKEN_LT i64 = 35;        // <
var TOKEN_GT i64 = 36;        // >
var TOKEN_LTEQ i64 = 37;      // <=
var TOKEN_GTEQ i64 = 38;      // >=
var TOKEN_AMPAMP i64 = 39;    // &&
var TOKEN_PIPEPIPE i64 = 40;  // ||

// Punctuation
var TOKEN_LPAREN i64 = 41;    // (
var TOKEN_RPAREN i64 = 42;    // )
var TOKEN_LBRACE i64 = 43;    // {
var TOKEN_RBRACE i64 = 44;    // }
var TOKEN_LBRACKET i64 = 45;  // [
var TOKEN_RBRACKET i64 = 46;  // ]
var TOKEN_COMMA i64 = 47;     // ,
var TOKEN_SEMICOLON i64 = 48; // ;
var TOKEN_DOT i64 = 49;       // .
var TOKEN_COLON i64 = 50;     // :
var TOKEN_COLONEQ i64 = 51;   // :=

// Macro tokens
var TOKEN_MACRO i64 = 52;         // 'macro' keyword
var TOKEN_DOLLAR_LBRACE i64 = 53; // ${ (quote start)
var TOKEN_DOLLAR i64 = 54;        // $ (unquote)
var TOKEN_DOLLAR_AT i64 = 55;     // $@ (unquote string as identifier)

// Reader macro tokens
var TOKEN_IMPORT i64 = 56;        // 'import' keyword
var TOKEN_READER i64 = 57;        // 'reader' keyword
var TOKEN_READER_MACRO i64 = 58;  // #name{...} reader macro invocation
var TOKEN_INCLUDE i64 = 59;       // 'include' keyword

// Bitwise operators
var TOKEN_PIPE i64 = 60;          // |
var TOKEN_CARET i64 = 61;         // ^
var TOKEN_LTLT i64 = 62;          // <<
var TOKEN_GTGT i64 = 63;          // >>

// Compound assignment
var TOKEN_PLUSEQ i64 = 64;        // +=
var TOKEN_MINUSEQ i64 = 65;       // -=
var TOKEN_STAREQ i64 = 66;        // *=
var TOKEN_SLASHEQ i64 = 67;       // /=
var TOKEN_PERCENTEQ i64 = 68;     // %=

// Loop control
var TOKEN_BREAK i64 = 69;         // break
var TOKEN_CONTINUE i64 = 70;      // continue

// ============================================================
// Token struct
// ============================================================

struct Token {
    type_tok i64;
    lexeme *u8;
    lexeme_len i64;
    line i64;
    col i64;
    content *u8;      // For reader macros: content between braces
    content_len i64;  // For reader macros: length of content
}

// Accessor functions for backward compatibility
// These cast *u8 to *Token and use field access

func tok_type(tok *u8) i64 {
    var t *Token = tok;
    return t.type_tok;
}

func tok_set_type(tok *u8, typ i64) void {
    var t *Token = tok;
    t.type_tok = typ;
}

func tok_lexeme(tok *u8) *u8 {
    var t *Token = tok;
    return t.lexeme;
}

func tok_set_lexeme(tok *u8, ptr *u8) void {
    var t *Token = tok;
    t.lexeme = ptr;
}

func tok_lexeme_len(tok *u8) i64 {
    var t *Token = tok;
    return t.lexeme_len;
}

func tok_set_lexeme_len(tok *u8, len i64) void {
    var t *Token = tok;
    t.lexeme_len = len;
}

func tok_line(tok *u8) i64 {
    var t *Token = tok;
    return t.line;
}

func tok_set_line(tok *u8, ln i64) void {
    var t *Token = tok;
    t.line = ln;
}

func tok_col(tok *u8) i64 {
    var t *Token = tok;
    return t.col;
}

func tok_set_col(tok *u8, c i64) void {
    var t *Token = tok;
    t.col = c;
}

func tok_content(tok *u8) *u8 {
    var t *Token = tok;
    return t.content;
}

func tok_set_content(tok *u8, ptr *u8) void {
    var t *Token = tok;
    t.content = ptr;
}

func tok_content_len(tok *u8) i64 {
    var t *Token = tok;
    return t.content_len;
}

func tok_set_content_len(tok *u8, len i64) void {
    var t *Token = tok;
    t.content_len = len;
}

func tok_alloc() *u8 {
    return alloc(56);  // 7 fields * 8 bytes
}

// ============================================================
// Lexer state (global)
// ============================================================

var lex_source *u8 = nil;
var lex_source_len i64 = 0;
var lex_start i64 = 0;
var lex_current i64 = 0;
var lex_line i64 = 1;
var lex_col i64 = 1;
var lex_start_col i64 = 1;

func lexer_init(source *u8) void {
    lex_source = source;
    lex_source_len = strlen(source);
    lex_start = 0;
    lex_current = 0;
    lex_line = 1;
    lex_col = 1;
    lex_start_col = 1;
}

// ============================================================
// Character helpers
// ============================================================

func is_alpha(c u8) bool {
    if c >= 97 {  // 'a'
        if c <= 122 {  // 'z'
            return true;
        }
    }
    if c >= 65 {  // 'A'
        if c <= 90 {  // 'Z'
            return true;
        }
    }
    if c == 95 {  // '_'
        return true;
    }
    return false;
}

func is_digit(c u8) bool {
    if c >= 48 {  // '0'
        if c <= 57 {  // '9'
            return true;
        }
    }
    return false;
}

func is_alphanumeric(c u8) bool {
    return is_alpha(c) || is_digit(c);
}

// ============================================================
// Lexer helpers
// ============================================================

func lex_is_at_end() bool {
    return lex_current >= lex_source_len;
}

func lex_peek() u8 {
    if lex_is_at_end() {
        return 0;
    }
    return *(lex_source + lex_current);
}

func lex_peek_next() u8 {
    if lex_current + 1 >= lex_source_len {
        return 0;
    }
    return *(lex_source + lex_current + 1);
}

func lex_advance() u8 {
    var c u8 = *(lex_source + lex_current);
    lex_current = lex_current + 1;
    lex_col = lex_col + 1;
    return c;
}

func lex_match(expected u8) bool {
    if lex_is_at_end() {
        return false;
    }
    if *(lex_source + lex_current) != expected {
        return false;
    }
    lex_current = lex_current + 1;
    lex_col = lex_col + 1;
    return true;
}

// ============================================================
// Token creation
// ============================================================

func make_token(tok_type i64) *u8 {
    var tok *u8 = tok_alloc();
    tok_set_type(tok, tok_type);
    tok_set_lexeme(tok, lex_source + lex_start);
    tok_set_lexeme_len(tok, lex_current - lex_start);
    tok_set_line(tok, lex_line);
    tok_set_col(tok, lex_start_col);
    return tok;
}

func error_token(msg *u8) *u8 {
    var tok *u8 = tok_alloc();
    tok_set_type(tok, TOKEN_ERROR);
    tok_set_lexeme(tok, msg);
    tok_set_lexeme_len(tok, strlen(msg));
    tok_set_line(tok, lex_line);
    tok_set_col(tok, lex_start_col);
    return tok;
}

// ============================================================
// Skip whitespace and comments
// ============================================================

func skip_block_comment() void {
    lex_advance();  // consume /
    lex_advance();  // consume *
    var done i64 = 0;
    while !lex_is_at_end() && done == 0 {
        if lex_peek() == 42 && lex_peek_next() == 47 {
            lex_advance();  // consume *
            lex_advance();  // consume /
            done = 1;
        } else {
            if lex_peek() == 10 {
                lex_line = lex_line + 1;
                lex_col = 0;
            }
            lex_advance();
        }
    }
}

func skip_whitespace() void {
    var done i64 = 0;
    while done == 0 {
        if lex_is_at_end() {
            done = 1;
        } else {
            var c u8 = lex_peek();

            if c == 32 || c == 9 || c == 13 {  // space, tab, CR
                lex_advance();
            } else if c == 10 {  // newline
                lex_line = lex_line + 1;
                lex_col = 0;
                lex_advance();
            } else if c == 47 {  // '/'
                if lex_peek_next() == 47 {  // '//' line comment
                    while !lex_is_at_end() && lex_peek() != 10 {
                        lex_advance();
                    }
                } else if lex_peek_next() == 42 {  // '/*' block comment
                    skip_block_comment();
                } else {
                    done = 1;
                }
            } else {
                done = 1;
            }
        }
    }
}

// ============================================================
// Keyword lookup
// ============================================================

// Check if lexeme matches a keyword, accounting for length
func lexeme_eq(kw *u8) bool {
    var kw_len i64 = strlen(kw);
    var lex_len i64 = lex_current - lex_start;
    if kw_len != lex_len {
        return false;
    }
    var i i64 = 0;
    while i < kw_len {
        if *(lex_source + lex_start + i) != *(kw + i) {
            return false;
        }
        i = i + 1;
    }
    return true;
}

func check_keyword() i64 {
    // Keywords
    if lexeme_eq("func") { return TOKEN_FUNC; }
    if lexeme_eq("var") { return TOKEN_VAR; }
    if lexeme_eq("struct") { return TOKEN_STRUCT; }
    if lexeme_eq("macro") { return TOKEN_MACRO; }
    if lexeme_eq("reader") { return TOKEN_READER; }
    if lexeme_eq("import") { return TOKEN_IMPORT; }
    if lexeme_eq("include") { return TOKEN_INCLUDE; }
    if lexeme_eq("if") { return TOKEN_IF; }
    if lexeme_eq("else") { return TOKEN_ELSE; }
    if lexeme_eq("while") { return TOKEN_WHILE; }
    if lexeme_eq("return") { return TOKEN_RETURN; }
    if lexeme_eq("break") { return TOKEN_BREAK; }
    if lexeme_eq("continue") { return TOKEN_CONTINUE; }
    if lexeme_eq("true") { return TOKEN_TRUE; }
    if lexeme_eq("false") { return TOKEN_FALSE; }
    if lexeme_eq("nil") { return TOKEN_NIL; }

    // Type keywords
    if lexeme_eq("i8") { return TOKEN_I8; }
    if lexeme_eq("i16") { return TOKEN_I16; }
    if lexeme_eq("i32") { return TOKEN_I32; }
    if lexeme_eq("i64") { return TOKEN_I64; }
    if lexeme_eq("u8") { return TOKEN_U8; }
    if lexeme_eq("u16") { return TOKEN_U16; }
    if lexeme_eq("u32") { return TOKEN_U32; }
    if lexeme_eq("u64") { return TOKEN_U64; }
    if lexeme_eq("bool") { return TOKEN_BOOL; }
    if lexeme_eq("void") { return TOKEN_VOID; }

    // Built-in (treated like keyword)
    if lexeme_eq("syscall") { return TOKEN_IDENT; }

    return TOKEN_IDENT;
}

// ============================================================
// Scan specific token types
// ============================================================

func scan_identifier() *u8 {
    while is_alphanumeric(lex_peek()) {
        lex_advance();
    }
    return make_token(check_keyword());
}

func scan_number() *u8 {
    while is_digit(lex_peek()) {
        lex_advance();
    }
    return make_token(TOKEN_NUMBER);
}

func scan_string() *u8 {
    while !lex_is_at_end() && lex_peek() != 34 {  // '"'
        if lex_peek() == 10 {  // newline
            lex_line = lex_line + 1;
            lex_col = 0;
        }
        if lex_peek() == 92 && lex_peek_next() != 0 {  // backslash escape
            lex_advance();  // consume backslash
        }
        lex_advance();
    }

    if lex_is_at_end() {
        return error_token("unterminated string");
    }

    lex_advance();  // closing quote
    return make_token(TOKEN_STRING);
}

// Scan character literal: 'A' or '\n'
// Returns TOKEN_NUMBER with the character value as lexeme
func scan_char() *u8 {
    // We've already consumed opening quote
    if lex_is_at_end() {
        return error_token("unterminated character literal");
    }

    var c u8 = lex_advance();
    var value i64 = 0;

    if c == 92 {  // backslash - escape sequence
        if lex_is_at_end() {
            return error_token("unterminated escape in character literal");
        }
        var esc u8 = lex_advance();
        if esc == 110 { value = 10; }       // \n -> newline
        else if esc == 116 { value = 9; }   // \t -> tab
        else if esc == 114 { value = 13; }  // \r -> carriage return
        else if esc == 48 { value = 0; }    // \0 -> null
        else if esc == 92 { value = 92; }   // \\ -> backslash
        else if esc == 39 { value = 39; }   // \' -> single quote
        else if esc == 34 { value = 34; }   // \" -> double quote
        else {
            return error_token("unknown escape sequence");
        }
    } else {
        value = c;
    }

    // Expect closing quote
    if lex_is_at_end() || lex_peek() != 39 {
        return error_token("unterminated character literal");
    }
    lex_advance();  // consume closing quote

    // Convert value to string and create NUMBER token
    var buf *u8 = alloc(16);
    var len i64 = itoa(value, buf);

    var tok *u8 = tok_alloc();
    tok_set_type(tok, TOKEN_NUMBER);
    tok_set_lexeme(tok, buf);
    tok_set_lexeme_len(tok, len);
    tok_set_line(tok, lex_line);
    tok_set_col(tok, lex_start_col);
    return tok;
}

// Scan reader macro: #name{content}
// Returns token with:
//   - lexeme = reader name
//   - content = text between balanced braces
func scan_reader_macro() *u8 {
    // We've already consumed '#', now read the name
    var name_start i64 = lex_current;

    // Read identifier (the reader macro name)
    if !is_alpha(lex_peek()) {
        return error_token("expected identifier after '#'");
    }
    while is_alphanumeric(lex_peek()) {
        lex_advance();
    }
    var name_end i64 = lex_current;
    var name_len i64 = name_end - name_start;

    // Expect '{'
    if lex_peek() != 123 {  // '{'
        return error_token("expected '{' after reader macro name");
    }
    lex_advance();  // consume '{'

    // Read balanced content
    var content_start i64 = lex_current;
    var brace_depth i64 = 1;

    while !lex_is_at_end() && brace_depth > 0 {
        var c u8 = lex_peek();

        if c == 123 {  // '{'
            brace_depth = brace_depth + 1;
            lex_advance();
        } else if c == 125 {  // '}'
            brace_depth = brace_depth - 1;
            if brace_depth > 0 {
                lex_advance();
            }
        } else if c == 34 {  // '"' - skip strings to not count braces inside
            lex_advance();  // consume opening quote
            while !lex_is_at_end() && lex_peek() != 34 {
                if lex_peek() == 92 && lex_peek_next() != 0 {  // escape
                    lex_advance();
                }
                if lex_peek() == 10 {
                    lex_line = lex_line + 1;
                    lex_col = 0;
                }
                lex_advance();
            }
            if !lex_is_at_end() {
                lex_advance();  // consume closing quote
            }
        } else if c == 10 {  // newline
            lex_line = lex_line + 1;
            lex_col = 0;
            lex_advance();
        } else {
            lex_advance();
        }
    }

    if brace_depth != 0 {
        return error_token("unterminated reader macro content");
    }

    var content_end i64 = lex_current;
    lex_advance();  // consume closing '}'

    // Create token
    var tok *u8 = tok_alloc();
    tok_set_type(tok, TOKEN_READER_MACRO);
    tok_set_lexeme(tok, lex_source + name_start);
    tok_set_lexeme_len(tok, name_len);
    tok_set_line(tok, lex_line);
    tok_set_col(tok, lex_start_col);
    tok_set_content(tok, lex_source + content_start);
    tok_set_content_len(tok, content_end - content_start);

    return tok;
}

// ============================================================
// Main scan function
// ============================================================

func scan_token() *u8 {
    skip_whitespace();
    lex_start = lex_current;
    lex_start_col = lex_col;

    if lex_is_at_end() {
        return make_token(TOKEN_EOF);
    }

    var c u8 = lex_advance();

    if is_alpha(c) {
        return scan_identifier();
    }
    if is_digit(c) {
        return scan_number();
    }

    // Single-char tokens
    if c == 40 { return make_token(TOKEN_LPAREN); }    // '('
    if c == 41 { return make_token(TOKEN_RPAREN); }    // ')'
    if c == 123 { return make_token(TOKEN_LBRACE); }   // '{'
    if c == 125 { return make_token(TOKEN_RBRACE); }   // '}'
    if c == 91 { return make_token(TOKEN_LBRACKET); }  // '['
    if c == 93 { return make_token(TOKEN_RBRACKET); }  // ']'
    if c == 44 { return make_token(TOKEN_COMMA); }     // ','
    if c == 59 { return make_token(TOKEN_SEMICOLON); } // ';'
    if c == 46 { return make_token(TOKEN_DOT); }       // '.'
    if c == 43 {  // '+'
        if lex_match(61) { return make_token(TOKEN_PLUSEQ); }  // '+='
        return make_token(TOKEN_PLUS);
    }
    if c == 45 {  // '-'
        if lex_match(61) { return make_token(TOKEN_MINUSEQ); }  // '-='
        return make_token(TOKEN_MINUS);
    }
    if c == 42 {  // '*'
        if lex_match(61) { return make_token(TOKEN_STAREQ); }  // '*='
        return make_token(TOKEN_STAR);
    }
    if c == 47 {  // '/'
        if lex_match(61) { return make_token(TOKEN_SLASHEQ); }  // '/='
        return make_token(TOKEN_SLASH);
    }
    if c == 37 {  // '%'
        if lex_match(61) { return make_token(TOKEN_PERCENTEQ); }  // '%='
        return make_token(TOKEN_PERCENT);
    }

    // Two-char tokens
    if c == 38 {  // '&'
        if lex_match(38) { return make_token(TOKEN_AMPAMP); }  // '&&'
        return make_token(TOKEN_AMP);
    }
    if c == 124 {  // '|'
        if lex_match(124) { return make_token(TOKEN_PIPEPIPE); }  // '||'
        return make_token(TOKEN_PIPE);  // bitwise or
    }
    if c == 94 {  // '^'
        return make_token(TOKEN_CARET);  // bitwise xor
    }
    if c == 33 {  // '!'
        if lex_match(61) { return make_token(TOKEN_BANGEQ); }  // '!='
        return make_token(TOKEN_BANG);
    }
    if c == 61 {  // '='
        if lex_match(61) { return make_token(TOKEN_EQEQ); }  // '=='
        return make_token(TOKEN_EQ);
    }
    if c == 60 {  // '<'
        if lex_match(60) { return make_token(TOKEN_LTLT); }   // '<<'
        if lex_match(61) { return make_token(TOKEN_LTEQ); }   // '<='
        return make_token(TOKEN_LT);
    }
    if c == 62 {  // '>'
        if lex_match(62) { return make_token(TOKEN_GTGT); }   // '>>'
        if lex_match(61) { return make_token(TOKEN_GTEQ); }   // '>='
        return make_token(TOKEN_GT);
    }
    if c == 58 {  // ':'
        if lex_match(61) { return make_token(TOKEN_COLONEQ); }  // ':='
        return make_token(TOKEN_COLON);
    }
    if c == 36 {  // '$'
        if lex_match(123) { return make_token(TOKEN_DOLLAR_LBRACE); }  // '${'
        if lex_match(64) { return make_token(TOKEN_DOLLAR_AT); }       // '$@'
        return make_token(TOKEN_DOLLAR);
    }
    if c == 35 {  // '#' - reader macro
        return scan_reader_macro();
    }
    if c == 34 {  // '"'
        return scan_string();
    }
    if c == 39 {  // '\''
        return scan_char();
    }

    return error_token("unexpected character");
}

// ============================================================
// Debug helpers
// ============================================================

func print_token_type(t i64) void {
    if t == TOKEN_EOF { print("EOF"); return; }
    if t == TOKEN_ERROR { print("ERROR"); return; }
    if t == TOKEN_IDENT { print("IDENT"); return; }
    if t == TOKEN_NUMBER { print("NUMBER"); return; }
    if t == TOKEN_STRING { print("STRING"); return; }
    if t == TOKEN_FUNC { print("func"); return; }
    if t == TOKEN_VAR { print("var"); return; }
    if t == TOKEN_STRUCT { print("struct"); return; }
    if t == TOKEN_IF { print("if"); return; }
    if t == TOKEN_ELSE { print("else"); return; }
    if t == TOKEN_WHILE { print("while"); return; }
    if t == TOKEN_RETURN { print("return"); return; }
    if t == TOKEN_TRUE { print("true"); return; }
    if t == TOKEN_FALSE { print("false"); return; }
    if t == TOKEN_NIL { print("nil"); return; }
    if t == TOKEN_I8 { print("i8"); return; }
    if t == TOKEN_I16 { print("i16"); return; }
    if t == TOKEN_I32 { print("i32"); return; }
    if t == TOKEN_I64 { print("i64"); return; }
    if t == TOKEN_U8 { print("u8"); return; }
    if t == TOKEN_U16 { print("u16"); return; }
    if t == TOKEN_U32 { print("u32"); return; }
    if t == TOKEN_U64 { print("u64"); return; }
    if t == TOKEN_BOOL { print("bool"); return; }
    if t == TOKEN_VOID { print("void"); return; }
    if t == TOKEN_PLUS { print("+"); return; }
    if t == TOKEN_MINUS { print("-"); return; }
    if t == TOKEN_STAR { print("*"); return; }
    if t == TOKEN_SLASH { print("/"); return; }
    if t == TOKEN_PERCENT { print("%"); return; }
    if t == TOKEN_AMP { print("&"); return; }
    if t == TOKEN_BANG { print("!"); return; }
    if t == TOKEN_EQ { print("="); return; }
    if t == TOKEN_EQEQ { print("=="); return; }
    if t == TOKEN_BANGEQ { print("!="); return; }
    if t == TOKEN_LT { print("<"); return; }
    if t == TOKEN_GT { print(">"); return; }
    if t == TOKEN_LTEQ { print("<="); return; }
    if t == TOKEN_GTEQ { print(">="); return; }
    if t == TOKEN_AMPAMP { print("&&"); return; }
    if t == TOKEN_PIPEPIPE { print("||"); return; }
    if t == TOKEN_LPAREN { print("("); return; }
    if t == TOKEN_RPAREN { print(")"); return; }
    if t == TOKEN_LBRACE { print("{"); return; }
    if t == TOKEN_RBRACE { print("}"); return; }
    if t == TOKEN_LBRACKET { print("["); return; }
    if t == TOKEN_RBRACKET { print("]"); return; }
    if t == TOKEN_COMMA { print(","); return; }
    if t == TOKEN_SEMICOLON { print(";"); return; }
    if t == TOKEN_DOT { print("."); return; }
    if t == TOKEN_COLON { print(":"); return; }
    if t == TOKEN_COLONEQ { print(":="); return; }
    if t == TOKEN_MACRO { print("macro"); return; }
    if t == TOKEN_DOLLAR_LBRACE { print("${"); return; }
    if t == TOKEN_DOLLAR { print("$"); return; }
    if t == TOKEN_DOLLAR_AT { print("$@"); return; }
    if t == TOKEN_IMPORT { print("import"); return; }
    if t == TOKEN_READER { print("reader"); return; }
    if t == TOKEN_READER_MACRO { print("READER_MACRO"); return; }
    if t == TOKEN_INCLUDE { print("include"); return; }
    if t == TOKEN_PIPE { print("|"); return; }
    if t == TOKEN_CARET { print("^"); return; }
    if t == TOKEN_LTLT { print("<<"); return; }
    if t == TOKEN_GTGT { print(">>"); return; }
    if t == TOKEN_PLUSEQ { print("+="); return; }
    if t == TOKEN_MINUSEQ { print("-="); return; }
    if t == TOKEN_STAREQ { print("*="); return; }
    if t == TOKEN_SLASHEQ { print("/="); return; }
    if t == TOKEN_PERCENTEQ { print("%="); return; }
    if t == TOKEN_BREAK { print("break"); return; }
    if t == TOKEN_CONTINUE { print("continue"); return; }
    print("UNKNOWN");
}

// Print n chars from a pointer
func print_n(s *u8, n i64) void {
    file_write(1, s, n);
}

func print_token(tok *u8) void {
    print("[");
    print_int(tok_line(tok));
    print(":");
    print_int(tok_col(tok));
    print("] ");
    print_token_type(tok_type(tok));
    print(" '");
    print_n(tok_lexeme(tok), tok_lexeme_len(tok));
    println("'");
}
